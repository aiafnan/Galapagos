{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be56db67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74899628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import types\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from clarifai.rest import ClarifaiApp\n",
    "from clarifai.rest import Image as ClImage\n",
    "from clarifai.rest import UserError\n",
    "from clarifai.rest import ModelOutputConfig, ModelOutputInfo\n",
    "\n",
    "# ADD CREDENTIALS HERE\n",
    "api_key = '63fb53f4bd904e788be7ec3697a9d68b'\n",
    "\n",
    "os.chdir('C:/Users/mahmud/Desktop/Research/Galapagos/Python/Flikr Scraping/Images/Tortoisefresh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd67f996",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_11184/1600518172.py, line 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\mahmud\\AppData\\Local\\Temp/ipykernel_11184/1600518172.py\"\u001b[1;36m, line \u001b[1;32m46\u001b[0m\n\u001b[1;33m    print \"Number of images to process: \" + str(len(data))\u001b[0m\n\u001b[1;37m                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# For printing unicode characters to the console.\n",
    "def encode(text):\n",
    "    if type(text) is list or type(text) is tuple:\n",
    "        return [x.encode('utf-8') for x in text]\n",
    "\n",
    "    elif type(text) is not int and type(text) is not float:\n",
    "        return text.encode('utf-8')\n",
    "\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Counter variables (Leave as is)\n",
    "index = 0\n",
    "counter = 0\n",
    "\n",
    "# Batch Size. 32 is the most optimal\n",
    "batch_size = 32\n",
    "\n",
    "# Editable Options for Concept Models (e.g. General, Food, Moderation, NSFW, etc.) and Custom Models\n",
    "# Note that the language can only be edited for the General Model\n",
    "max_concepts = 20\n",
    "min_prediction_value = 0.75\n",
    "language = \"en\"\n",
    "\n",
    "# Concept Filter - use if you want to filter by ONLY these. Blank by default, and can only be used on concept and custom models\n",
    "# e.g. concept_filter = ['word1', 'word2']\n",
    "concept_filter = ['tortoise']\n",
    "\n",
    "# Input and Output Files - Edit these\n",
    "input_file = 'tortoise.csv'\n",
    "output_file = 'finaloutcome.csv'\n",
    "\n",
    "# Instantiate the app\n",
    "app = ClarifaiApp(api_key=api_key)\n",
    "\n",
    "# MODEL - (Edit this)\n",
    "# PUBLIC\n",
    "model = app.public_models.general_model\n",
    "\n",
    "# CUSTOM\n",
    "# model = app.models.get(\"model_name\")\n",
    "\n",
    "with open(input_file, 'rb') as file_with_urls:\n",
    "    data = list(csv.DictReader(file_with_urls, delimiter=','))\n",
    "    row_count = len(data)\n",
    "    print \"Number of images to process: \" + str(len(data))\n",
    "\n",
    "with open(output_file, mode='w') as file_to_write_to:\n",
    "    data_writer = csv.writer(file_to_write_to, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    while (counter < row_count):\n",
    "        print \"Processing batch \" + str(index+1)\n",
    "        print \"Images Predicted So Far = \" + str(counter)\n",
    "\n",
    "    # Batch Image List\n",
    "    imageList=[]\n",
    "\n",
    "    if row_count > counter + batch_size:\n",
    "        range_limit = counter + batch_size\n",
    "\n",
    "    else:\n",
    "        range_limit = row_count - counter\n",
    "\n",
    "    for x in range(counter, range_limit):\n",
    "        try:\n",
    "        imageList.append(ClImage(url=data[x][\"image_path\"]))\n",
    "        \n",
    "        except IndexError:\n",
    "            print err\n",
    "        break\n",
    "        \n",
    "        except UserError as err:\n",
    "            print err\n",
    "            \n",
    "        except AttributeError as err:\n",
    "        print err\n",
    "        continue\n",
    "\n",
    "    # Get predictions for those images\n",
    "    if model.model_id in [\"eeed0b6733a644cea07cf4c60f87ebb7\", \"c0c0ac362b03416da06ab3fa36fb58e3\", \"a403429f2ddf4b49b307e318f00e528b\", \"e466caa0619f444ab97497640cefc4dc\"]:\n",
    "        batch_predict = model.predict(imageList)\n",
    "\n",
    "    else:\n",
    "        model_output_info = ModelOutputInfo(\n",
    "                output_config=ModelOutputConfig(\n",
    "                language=language, \n",
    "                min_value=min_prediction_value, \n",
    "                max_concepts=max_concepts, \n",
    "                select_concepts=concept_filter))\n",
    "\n",
    "        batch_predict = model.predict(imageList, model_output_info)\n",
    "\n",
    "    for item in batch_predict[\"outputs\"]:\n",
    "        row_output = []\n",
    "        row_output.append(encode(item[\"input\"][\"data\"][\"image\"][\"url\"]))\n",
    "\n",
    "      # Check for Model Type (Concept, Colors or Detection)\n",
    "\n",
    "      # CONCEPT MODELS\n",
    "        if \"concepts\" in item[\"data\"]:\n",
    "        for prediction in item[\"data\"][\"concepts\"]:\n",
    "            row_output.append(encode(prediction[\"name\"]))\n",
    "            row_output.append(encode(prediction[\"value\"]))\n",
    "\n",
    "            data_writer.writerow(row_output)\n",
    "\n",
    "    counter = counter + batch_size\n",
    "    index = index+1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5728784e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geostats_env",
   "language": "python",
   "name": "geostats_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
