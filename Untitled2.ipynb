{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a66f62d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ce8f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import types\n",
    "import sys\n",
    "\n",
    "from clarifai.rest import ClarifaiApp\n",
    "from clarifai.rest import Image as ClImage\n",
    "from clarifai.rest import UserError\n",
    "from clarifai.rest import ModelOutputConfig, ModelOutputInfo\n",
    "\n",
    "# ADD CREDENTIALS HERE\n",
    "api_key = '63fb53f4bd904e788be7ec3697a9d68b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613353eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# For printing unicode characters to the console.\n",
    "def encode(text):\n",
    "  if type(text) is list or type(text) is tuple:\n",
    "    return [x.encode('utf-8') for x in text]\n",
    "\n",
    "  elif type(text) is not int and type(text) is not float:\n",
    "    return text.encode('utf-8')\n",
    "\n",
    "  else:\n",
    "    return text\n",
    "\n",
    "# Counter variables (Leave as is)\n",
    "index = 0\n",
    "counter = 0\n",
    "\n",
    "# Batch Size. 32 is the most optimal\n",
    "batch_size = 32\n",
    "\n",
    "# Editable Options for Concept Models (e.g. General, Food, Moderation, NSFW, etc.) and Custom Models\n",
    "# Note that the language can only be edited for the General Model\n",
    "max_concepts = 20\n",
    "min_prediction_value = 0.75\n",
    "language = \"en\"\n",
    "\n",
    "# Concept Filter - use if you want to filter by ONLY these. Blank by default, and can only be used on concept and custom models\n",
    "# e.g. concept_filter = ['word1', 'word2']\n",
    "concept_filter = []\n",
    "\n",
    "# Input and Output Files - Edit these\n",
    "input_file = '/where/your/urls/are.csv'\n",
    "output_file = '/where/the/results/should/go.csv'\n",
    "\n",
    "# Instantiate the app\n",
    "app = ClarifaiApp(api_key=api_key)\n",
    "\n",
    "# MODEL - (Edit this)\n",
    "# PUBLIC\n",
    "model = app.public_models.demographics_model\n",
    "\n",
    "# CUSTOM\n",
    "# model = app.models.get(\"model_name\")\n",
    "\n",
    "with open(input_file, 'rb') as file_with_urls:\n",
    "  data = list(csv.DictReader(file_with_urls, delimiter=','))\n",
    "  row_count = len(data)\n",
    "  print \"Number of images to process: \" + str(len(data))\n",
    "\n",
    "with open(output_file, mode='w') as file_to_write_to:\n",
    "  data_writer = csv.writer(file_to_write_to, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "  while (counter < row_count):\n",
    "    print \"Processing batch \" + str(index+1)\n",
    "    print \"Images Predicted So Far = \" + str(counter)\n",
    "\n",
    "    # Batch Image List\n",
    "    imageList=[]\n",
    "\n",
    "    if row_count > counter + batch_size:\n",
    "      range_limit = counter + batch_size\n",
    "\n",
    "    else:\n",
    "      range_limit = row_count - counter\n",
    "\n",
    "    for x in range(counter, range_limit):\n",
    "      try:\n",
    "        imageList.append(ClImage(url=data[x][\"image_path\"]))\n",
    "\n",
    "      except IndexError:\n",
    "        print err\n",
    "        break\n",
    "\n",
    "      except UserError as err:\n",
    "        print err\n",
    "\n",
    "      except AttributeError as err:\n",
    "        print err\n",
    "        continue\n",
    "\n",
    "    # Get predictions for those images\n",
    "    if model.model_id in [\"eeed0b6733a644cea07cf4c60f87ebb7\", \"c0c0ac362b03416da06ab3fa36fb58e3\", \"a403429f2ddf4b49b307e318f00e528b\", \"e466caa0619f444ab97497640cefc4dc\"]:\n",
    "      batch_predict = model.predict(imageList)\n",
    "\n",
    "    else:\n",
    "      model_output_info = ModelOutputInfo(\n",
    "                output_config=ModelOutputConfig(\n",
    "                language=language, \n",
    "                min_value=min_prediction_value, \n",
    "                max_concepts=max_concepts, \n",
    "                select_concepts=concept_filter))\n",
    "\n",
    "      batch_predict = model.predict(imageList, model_output_info)\n",
    "\n",
    "    for item in batch_predict[\"outputs\"]:\n",
    "      row_output = []\n",
    "      row_output.append(encode(item[\"input\"][\"data\"][\"image\"][\"url\"]))\n",
    "\n",
    "      # Check for Model Type (Concept, Colors or Detection)\n",
    "\n",
    "      # CONCEPT MODELS\n",
    "      if \"concepts\" in item[\"data\"]:\n",
    "        for prediction in item[\"data\"][\"concepts\"]:\n",
    "          row_output.append(encode(prediction[\"name\"]))\n",
    "          row_output.append(encode(prediction[\"value\"]))\n",
    "\n",
    "      # COLOR MODEL\n",
    "      elif \"colors\" in item[\"data\"]:\n",
    "        for prediction in item[\"data\"][\"colors\"]:\n",
    "          row_output.append(encode(prediction[\"w3c\"][\"name\"]))\n",
    "          row_output.append(encode(prediction[\"value\"]))     \n",
    "       \n",
    "      # DETECTION MODELS\n",
    "      elif \"regions\" in item[\"data\"]:      \n",
    "        # Demographics\n",
    "        if model.model_id == \"c0c0ac362b03416da06ab3fa36fb58e3\":\n",
    "          for region in item[\"data\"][\"regions\"]:\n",
    "            for ethnicity in region[\"data\"][\"face\"][\"multicultural_appearance\"][\"concepts\"]:\n",
    "              row_output.append(encode(ethnicity[\"name\"]))\n",
    "              row_output.append(encode(ethnicity[\"value\"]))              \n",
    "\n",
    "            row_output.append(encode(region[\"data\"][\"face\"][\"gender_appearance\"][\"concepts\"][0][\"name\"]))\n",
    "            row_output.append(encode(region[\"data\"][\"face\"][\"gender_appearance\"][\"concepts\"][0][\"value\"]))           \n",
    "\n",
    "            for age in region[\"data\"][\"face\"][\"age_appearance\"][\"concepts\"]:\n",
    "              row_output.append(\"Age:\" + encode(age[\"name\"]))\n",
    "              row_output.append(encode(age[\"value\"]))\n",
    "        \n",
    "        # Celebrity     \n",
    "        if model.model_id == \"e466caa0619f444ab97497640cefc4dc\":\n",
    "          if \"regions\" in item[\"data\"]:\n",
    "            for region in item[\"data\"][\"regions\"]:\n",
    "              for celeb in region[\"data\"][\"face\"][\"identity\"][\"concepts\"]:\n",
    "                row_output.append(encode(celeb[\"name\"]))\n",
    "                row_output.append(encode(celeb[\"value\"]))\n",
    "\n",
    "        # Face Detection\n",
    "        if model.model_id == \"a403429f2ddf4b49b307e318f00e528b\":\n",
    "          if \"regions\" in item[\"data\"]:\n",
    "            for region in item[\"data\"][\"regions\"]:\n",
    "              row_output.append(encode(\"Top Row:\" + region[\"region_info\"][\"bounding_box\"][\"top_row\"]))\n",
    "              row_output.append(encode(\"Left Col:\" + region[\"region_info\"][\"bounding_box\"][\"left_col\"]))\n",
    "              row_output.append(encode(\"Bottom Row:\" + region[\"region_info\"][\"bounding_box\"][\"bottom_row\"]))\n",
    "              row_output.append(encode(\"Right Col:\" + region[\"region_info\"][\"bounding_box\"][\"right_col\"]))\n",
    "\n",
    "      data_writer.writerow(row_output)\n",
    "\n",
    "    counter = counter + batch_size\n",
    "    index = index+1\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geostats_env",
   "language": "python",
   "name": "geostats_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
