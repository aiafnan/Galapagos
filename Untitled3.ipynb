{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5c816b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import types\n",
    "import sys\n",
    "import os\n",
    "from google.protobuf.struct_pb2 import Struct\n",
    "from clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\n",
    "from clarifai_grpc.grpc.api import service_pb2_grpc\n",
    "from clarifai_grpc.grpc.api.status import status_code_pb2\n",
    "from clarifai_grpc.grpc.api import service_pb2, resources_pb2\n",
    "from clarifai_grpc.grpc.api.status import status_code_pb2\n",
    "stub = service_pb2_grpc.V2Stub(ClarifaiChannel.get_grpc_channel())\n",
    "metadata = (('authorization', 'Key {}'.format('63fb53f4bd904e788be7ec3697a9d68b')),)\n",
    "# ADD CREDENTIALS HERE\n",
    "#api_key = '63fb53f4bd904e788be7ec3697a9d68b'\n",
    "\n",
    "os.chdir('C:/Users/mahmud/Desktop/Research/Galapagos/Python/Flikr Scraping/Images/Tortoise1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9574bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from google.protobuf.struct_pb2 import Struct\n",
    "import time\n",
    "\n",
    "from clarifai_grpc.grpc.api import service_pb2_grpc, service_pb2, resources_pb2\n",
    "from clarifai_grpc.grpc.api.status import status_code_pb2\n",
    "from clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\n",
    "stub = service_pb2_grpc.V2Stub(ClarifaiChannel.get_grpc_channel())\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "file_address = 'C:/Users/mahmud/Desktop/Research/Galapagos/Python/Flikr Scraping/Images/Tortoisefresh/tortoise_.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2007e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_address, mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    line_count = 0\n",
    "    inputs = [];\n",
    "    count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "        input_metadata = Struct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b81323f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'input.data.image.url'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6080/3069276123.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m input_metadata.update(\n\u001b[1;32m----> 2\u001b[1;33m             {\"metadata_field1\": row[\"input.data.image.url\"], \"metadata_field2\": row[\"input.data.concepts[0].id\"], \"metadata_field3\": row[\"input.data.concepts[0].value\"],\"metadata_field4\": row[\"input.data.geo.geo_point.latitude\"], \"metadata_field5\": row[\"input.data.geo.geo_point.longitude\"]\n\u001b[0m\u001b[0;32m      3\u001b[0m              })\n\u001b[0;32m      4\u001b[0m inputs.append(\n\u001b[0;32m      5\u001b[0m     resources_pb2.Input(\n",
      "\u001b[1;31mKeyError\u001b[0m: 'input.data.image.url'"
     ]
    }
   ],
   "source": [
    "\n",
    "input_metadata.update(\n",
    "            {\"metadata_field1\": row[\"input.data.image.url\"], \"metadata_field2\": row[\"input.data.concepts[0].id\"], \"metadata_field3\": row[\"input.data.concepts[0].value\"],\"metadata_field4\": row[\"input.data.geo.geo_point.latitude\"], \"metadata_field5\": row[\"input.data.geo.geo_point.longitude\"]\n",
    "             })\n",
    "inputs.append(\n",
    "    resources_pb2.Input(\n",
    "        data=resources_pb2.Data(\n",
    "            image=resources_pb2.Image(\n",
    "                url=row[\"input.data.image.url\"]\n",
    "            ),\n",
    "            metadata=input_metadata\n",
    "                    )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfa1cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_filter = ['tortoise']\n",
    "\n",
    "# Input and Output Files - Edit these\n",
    "input_file = 'tortoise.csv'\n",
    "output_file = 'outcome.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e91eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = service_pb2.PostModelOutputsRequest(\n",
    "\n",
    "   # This is the model ID of a publicly available General model. You may use any other public or custom model ID.\n",
    "   model_id='aaa03c23b3724a16a56b629203edc62c',\n",
    "   inputs=[\n",
    "     resources_pb2.Input(data=resources_pb2.Data(image=resources_pb2.Image(base64=input_file.getvalue())))\n",
    "   ])\n",
    "response = stub.PostModelOutputs(request, metadata=metadata)\n",
    "\n",
    "if response.status.code != status_code_pb2.SUCCESS:\n",
    "   raise Exception(\"Request failed, status code: \" + str(response.status.code))\n",
    "\n",
    "names = []\n",
    "confidences = []\n",
    "for concept in response.outputs[0].data.concepts:\n",
    "   names.append(concept.name)\n",
    "   confidences.append(concept.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33306c43",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7768/2910144131.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# Instantiate the app\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mapp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClarifaiApp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# MODEL - (Edit this)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\geostats_env\\lib\\site-packages\\clarifai\\rest\\client.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, app_id, app_secret, base_url, api_key, quiet, log_level)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcepts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConcepts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: Concepts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: Inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: Models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkflows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWorkflows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: Workflows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\geostats_env\\lib\\site-packages\\clarifai\\rest\\client.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, api, solutions)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[1;31m# the cache of the model name -> model id mapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m     \u001b[1;31m# to avoid an extra model query on every prediction by model name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_id_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_model_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0minit_model_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\geostats_env\\lib\\site-packages\\clarifai\\rest\\client.py\u001b[0m in \u001b[0;36minit_model_cache\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1086\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m         \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m         \u001b[0mmodel_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m         \u001b[0mmodel_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[0mmodel_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'type'"
     ]
    }
   ],
   "source": [
    "\n",
    "# For printing unicode characters to the console.\n",
    "def encode(text):\n",
    "\tif type(text) is list or type(text) is tuple:\n",
    "\t\treturn [x.encode('utf-8') for x in text]\n",
    "\telif type(text) is not int and type(text) is not float:\n",
    "\t\treturn text.encode('utf-8')\n",
    "\telse:\n",
    "\t\treturn text\n",
    "\n",
    "# Counter variables (Leave as is)\n",
    "index = 0\n",
    "counter = 0\n",
    "\n",
    "# Batch Size. 32 is the most optimal\n",
    "batch_size = 32\n",
    "\n",
    "# Editable Options for Concept Models (e.g. General, Food, Moderation, NSFW, etc.) and Custom Models\n",
    "# Note that the language can only be edited for the General Model\n",
    "max_concepts = 20\n",
    "min_prediction_value = 0.75\n",
    "language = \"en\"\n",
    "\n",
    "# Concept Filter - use if you want to filter by ONLY these. Blank by default, and can only be used on concept and custom models\n",
    "# e.g. concept_filter = ['word1', 'word2']\n",
    "concept_filter = ['tortoise']\n",
    "\n",
    "# Input and Output Files - Edit these\n",
    "input_file = 'tortoise.csv'\n",
    "output_file = 'outcome.csv'\n",
    "\n",
    "# Instantiate the app\n",
    "#app = ClarifaiApp(api_key= api_key)\n",
    "\n",
    "# MODEL - (Edit this)\n",
    "# PUBLIC\n",
    "model = app.public_models.general_model\n",
    "\n",
    "# CUSTOM\n",
    "# model = app.models.get(\"model_name\")\n",
    "\n",
    "with open(input_file, 'rb') as file_with_urls:\n",
    "    data = list(csv.DictReader(file_with_urls, delimiter=','))\n",
    "    row_count = len(data)\n",
    "    print (\"Number of images to process=\" + str(len(data)))\n",
    "\n",
    "with open(output_file, mode='w') as file_to_write_to:\n",
    "\tdata_writer = csv.writer(file_to_write_to, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "\t\n",
    "\twhile (counter < row_count):\n",
    "\t\tprint (\"Processing batch \" + str(index+1))\n",
    "\t\tprint (\"Counter = \" + str(counter))\n",
    "\t\t\n",
    "\t  # Batch Image List\n",
    "\t\timageList=[]\n",
    "\n",
    "\t\tif row_count > counter + batch_size:\n",
    "\t\t\trange_limit = counter + batch_size\n",
    "\t\telse:\n",
    "\t\t\trange_limit = row_count - counter\n",
    "\t\t\t\n",
    "\t\tfor x in range(counter, range_limit):\n",
    "\t\t\ttry:\n",
    "\t\t\t\timageList.append(ClImage(url=data[x][\"image_path\"]))\n",
    "\t\t\t\n",
    "\t\t\texcept IndexError:\n",
    "\t\t\t\tprint (err)\n",
    "\t\t\t\tbreak\n",
    "\t\t\t\n",
    "\t\t\texcept UserError as err:\n",
    "\t\t\t\tprint (err)\n",
    "\t\t\t\n",
    "\t\t\texcept AttributeError as err:\n",
    "\t\t\t\tprint (err)\n",
    "\t\t\t\tcontinue\n",
    "\t\t\n",
    "\t\t# Get predictions for those images\n",
    "\t\tif model.model_id in [\"eeed0b6733a644cea07cf4c60f87ebb7\", \"c0c0ac362b03416da06ab3fa36fb58e3\", \"a403429f2ddf4b49b307e318f00e528b\", \"e466caa0619f444ab97497640cefc4dc\"]:\n",
    "\t\t\tbatch_predict = model.predict(imageList)\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tmodel_output_info = ModelOutputInfo(\n",
    "\t\t\t\t\t\t\t\toutput_config=ModelOutputConfig(\n",
    "\t\t\t\t\t\t\t\tlanguage=language, \n",
    "\t\t\t\t\t\t\t\tmin_value=min_prediction_value, \n",
    "\t\t\t\t\t\t\t\tmax_concepts=max_concepts, \n",
    "\t\t\t\t\t\t\t\tselect_concepts=concept_filter))\n",
    "\n",
    "\t\t\tbatch_predict = model.predict(imageList, model_output_info)\n",
    "\t\t\t\n",
    "\t\tfor item in batch_predict[\"outputs\"]:\n",
    "\t\t\trow_output = []\n",
    "\t\t\trow_output.append(encode(item[\"input\"][\"data\"][\"image\"][\"url\"]))\n",
    "\t  \t\n",
    "\t  \t# Check for Model Type (Concept, Colors or Detection)\n",
    "\t  \t\n",
    "\t  \t# CONCEPT MODELS\n",
    "\t\t\tif \"concepts\" in item[\"data\"]:\n",
    "\t\t\t\tfor prediction in item[\"data\"][\"concepts\"]:\n",
    "\t\t\t\t\trow_output.append(encode(prediction[\"name\"]))\n",
    "\t\t\t\t\trow_output.append(encode(prediction[\"value\"]))\n",
    "\t  \t\t\t\n",
    "\t  \t\n",
    "\t\t\tdata_writer.writerow(row_output)\n",
    "\t  \t\n",
    "\t\tcounter = counter + batch_size\n",
    "\t\tindex = index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222f9b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geostats_env",
   "language": "python",
   "name": "geostats_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
